{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We started by \n",
    "* building intuition for model based learning, \n",
    "* explored how the linear regression model worked,\n",
    "* understood how the two different approaches to model fitting worked, and \n",
    "* some techniques for cleaning, transforming, and selecting features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we will practice what we learned by exploring ways to improve the models we built. We'll work with housing data for the city of Ames, Iowa, United States from 2006 to 2010."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.options.display.max_columns = 999\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"AmesHousing.txt\", delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_features(df):\n",
    "    return df\n",
    "\n",
    "def select_features(df):\n",
    "    return df[[\"Gr Liv Area\", \"SalePrice\"]]\n",
    "\n",
    "def train_and_test(df):  \n",
    "    train = df[:1460]\n",
    "    test = df[1460:]\n",
    "    numeric_train = train.select_dtypes(include = [\"integer\", \"float\"])\n",
    "    numeric_test = test.select_dtypes(include = [\"integer\", \"float\"])\n",
    "    \n",
    "    features = numeric_train.columns.drop(\"SalePrice\")\n",
    "    target = \"SalePrice\"\n",
    "    \n",
    "    lr = LinearRegression()\n",
    "    lr.fit(train[features], train[target])\n",
    "    predictions = lr.predict(test[features])\n",
    "    mse = mean_squared_error(test[target], predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57088.25161263909"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_df = transform_features(df)\n",
    "filtered_df = select_features(transform_df)\n",
    "rmse = train_and_test(filtered_df)\n",
    "\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "* Handle missing values:\n",
    " * All columns:\n",
    "      * Drop any with 5% or more missing values for now.\n",
    " * Text columns:\n",
    "      * Drop any with 1 or more missing values for now.\n",
    " * Numerical columns:\n",
    "      * For columns with missing values, fill in with the most common value in that column\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. All columns: Drop any with 5% or more missing values for now.\n",
    "\n",
    "num_missing = df.isnull().sum()\n",
    "\n",
    "drop_missing_cols = num_missing[num_missing > len(df)/20].sort_values()\n",
    "\n",
    "df = df.drop(drop_missing_cols.index, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2: Text columns: Drop any with 1 or more missing values for now.\n",
    "\n",
    "text_mv_counts = df.select_dtypes(include = [\"object\"]).isnull().sum().sort_values(ascending = False)\n",
    "\n",
    "drop_missing_cols_2 = text_mv_counts[text_mv_counts > 0]\n",
    "df = df.drop(drop_missing_cols_2.index, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Order               0\n",
       "Mo Sold             0\n",
       "Misc Val            0\n",
       "Pool Area           0\n",
       "Screen Porch        0\n",
       "3Ssn Porch          0\n",
       "Enclosed Porch      0\n",
       "Open Porch SF       0\n",
       "Wood Deck SF        0\n",
       "Fireplaces          0\n",
       "TotRms AbvGrd       0\n",
       "Kitchen AbvGr       0\n",
       "Bedroom AbvGr       0\n",
       "Half Bath           0\n",
       "Full Bath           0\n",
       "Yr Sold             0\n",
       "SalePrice           0\n",
       "MS SubClass         0\n",
       "Low Qual Fin SF     0\n",
       "2nd Flr SF          0\n",
       "1st Flr SF          0\n",
       "Overall Qual        0\n",
       "Overall Cond        0\n",
       "Year Built          0\n",
       "Year Remod/Add      0\n",
       "Lot Area            0\n",
       "Gr Liv Area         0\n",
       "PID                 0\n",
       "Garage Area         1\n",
       "BsmtFin SF 2        1\n",
       "Bsmt Unf SF         1\n",
       "Total Bsmt SF       1\n",
       "BsmtFin SF 1        1\n",
       "Garage Cars         1\n",
       "Bsmt Full Bath      2\n",
       "Bsmt Half Bath      2\n",
       "Mas Vnr Area       23\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3: Numerical columns: For columns with missing values, fill in with the most common value in that column\n",
    "\n",
    "num_missing = df.select_dtypes(include = [\"integer\", \"float\"]).isnull().sum().sort_values()\n",
    "num_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Order': 1,\n",
       " 'Mo Sold': 6.0,\n",
       " 'Misc Val': 0.0,\n",
       " 'Pool Area': 0.0,\n",
       " 'Screen Porch': 0.0,\n",
       " '3Ssn Porch': 0.0,\n",
       " 'Enclosed Porch': 0.0,\n",
       " 'Open Porch SF': 0.0,\n",
       " 'Wood Deck SF': 0.0,\n",
       " 'Fireplaces': 0.0,\n",
       " 'TotRms AbvGrd': 6.0,\n",
       " 'Kitchen AbvGr': 1.0,\n",
       " 'Bedroom AbvGr': 3.0,\n",
       " 'Half Bath': 0.0,\n",
       " 'Full Bath': 2.0,\n",
       " 'Yr Sold': 2007.0,\n",
       " 'SalePrice': 135000.0,\n",
       " 'MS SubClass': 20.0,\n",
       " 'Low Qual Fin SF': 0.0,\n",
       " '2nd Flr SF': 0.0,\n",
       " '1st Flr SF': 864.0,\n",
       " 'Overall Qual': 5.0,\n",
       " 'Overall Cond': 5.0,\n",
       " 'Year Built': 2005.0,\n",
       " 'Year Remod/Add': 1950.0,\n",
       " 'Lot Area': 9600.0,\n",
       " 'Gr Liv Area': 864.0,\n",
       " 'PID': 526301100,\n",
       " 'Garage Area': 0.0,\n",
       " 'BsmtFin SF 2': 0.0,\n",
       " 'Bsmt Unf SF': 0.0,\n",
       " 'Total Bsmt SF': 0.0,\n",
       " 'BsmtFin SF 1': 0.0,\n",
       " 'Garage Cars': 2.0,\n",
       " 'Bsmt Full Bath': 0.0,\n",
       " 'Bsmt Half Bath': 0.0,\n",
       " 'Mas Vnr Area': 0.0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the most common value for each column in `fixable_nmeric_missing_cols`.\n",
    "\n",
    "replacement_values_dict = df[num_missing.index].mode().to_dict(orient = \"record\")[0]\n",
    "replacement_values_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(replacement_values_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    64\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify that every column has 0 missing values\n",
    "df.isnull().sum().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What new features can we create, that better capture the information in some of the features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2180   -1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years_sold = df['Yr Sold'] - df['Year Built']\n",
    "years_sold[years_sold < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1702   -1\n",
       "2180   -2\n",
       "2181   -1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years_since_remod = df['Yr Sold'] - df['Year Remod/Add']\n",
    "years_since_remod[years_since_remod < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new columns\n",
    "df['Years Before Sale'] = years_sold\n",
    "df['Years Since Remod'] = years_since_remod\n",
    "\n",
    "df = df.drop([1702,2180,2181])\n",
    "\n",
    "df.drop([\"Year Built\", \"Year Remod/Add\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop columns that:\n",
    "\n",
    "* that aren't useful for ML\n",
    "* leak data about the final sale, read more about columns [here](http://jse.amstat.org/v19n3/decock/DataDocumentation.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns that aren't useful for ML\n",
    "df = df.drop([\"PID\", \"Order\"], axis=1)\n",
    "\n",
    "# Drop columns that leak info about the final sale\n",
    "df = df.drop([\"Mo Sold\", \"Sale Condition\", \"Sale Type\", \"Yr Sold\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_features(df):\n",
    "    num_missing = df.isnull().sum()\n",
    "    drop_missing_cols = num_missing[num_missing > len(df)/20].sort_values()\n",
    "    df = df.drop(drop_missing_cols.index, axis = 1)\n",
    "    \n",
    "    text_mv_counts = df.select_dtypes(include = [\"object\"]).isnull().sum().sort_values(ascending = False)\n",
    "    drop_missing_cols_2 = text_mv_counts[text_mv_counts > 0]\n",
    "    df = df.drop(drop_missing_cols_2.index, axis = 1)\n",
    "    \n",
    "    num_missing = df.select_dtypes(include = [\"integer\", \"float\"]).isnull().sum().sort_values()\n",
    "    replacement_values_dict = df[num_missing.index].mode().to_dict(orient = \"record\")[0]\n",
    "    df = df.fillna(replacement_values_dict)\n",
    "    \n",
    "    years_sold = df['Yr Sold'] - df['Year Built']\n",
    "    years_since_remod = df['Yr Sold'] - df['Year Remod/Add']\n",
    "    df['Years Before Sale'] = years_sold\n",
    "    df['Years Since Remod'] = years_since_remod\n",
    "    df = df.drop([1702,2180,2181])\n",
    "    df.drop([\"Year Built\", \"Year Remod/Add\"], axis = 1, inplace = True)\n",
    "    df = df.drop([\"PID\", \"Order\"], axis=1)\n",
    "    df = df.drop([\"Mo Sold\", \"Sale Condition\", \"Sale Type\", \"Yr Sold\"], axis=1)\n",
    "    return df\n",
    "\n",
    "def select_features(df):\n",
    "    return df[[\"Gr Liv Area\", \"SalePrice\"]]\n",
    "\n",
    "def train_and_test(df):  \n",
    "    train = df[:1460]\n",
    "    test = df[1460:]\n",
    "    numeric_train = train.select_dtypes(include = [\"integer\", \"float\"])\n",
    "    numeric_test = test.select_dtypes(include = [\"integer\", \"float\"])\n",
    "    \n",
    "    features = numeric_train.columns.drop(\"SalePrice\")\n",
    "    target = \"SalePrice\"\n",
    "    \n",
    "    lr = LinearRegression()\n",
    "    lr.fit(train[features], train[target])\n",
    "    predictions = lr.predict(test[features])\n",
    "    mse = mean_squared_error(test[target], predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "55275.367312413066"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"AmesHousing.txt\", delimiter=\"\\t\")\n",
    "transform_df = transform_features(df)\n",
    "filtered_df = select_features(transform_df)\n",
    "rmse = train_and_test(filtered_df)\n",
    "\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2930, 39)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_df = df.select_dtypes(include = [\"integer\", \"float\"])\n",
    "numerical_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BsmtFin SF 2       0.005891\n",
       "Misc Val           0.015691\n",
       "Yr Sold            0.030569\n",
       "Order              0.031408\n",
       "3Ssn Porch         0.032225\n",
       "Mo Sold            0.035259\n",
       "Bsmt Half Bath     0.035835\n",
       "Low Qual Fin SF    0.037660\n",
       "Pool Area          0.068403\n",
       "MS SubClass        0.085092\n",
       "Overall Cond       0.101697\n",
       "Screen Porch       0.112151\n",
       "Kitchen AbvGr      0.119814\n",
       "Enclosed Porch     0.128787\n",
       "Bedroom AbvGr      0.143913\n",
       "Bsmt Unf SF        0.182855\n",
       "PID                0.246521\n",
       "Lot Area           0.266549\n",
       "2nd Flr SF         0.269373\n",
       "Bsmt Full Bath     0.276050\n",
       "Half Bath          0.285056\n",
       "Open Porch SF      0.312951\n",
       "Wood Deck SF       0.327143\n",
       "Lot Frontage       0.357318\n",
       "BsmtFin SF 1       0.432914\n",
       "Fireplaces         0.474558\n",
       "TotRms AbvGrd      0.495474\n",
       "Mas Vnr Area       0.508285\n",
       "Garage Yr Blt      0.526965\n",
       "Year Remod/Add     0.532974\n",
       "Full Bath          0.545604\n",
       "Year Built         0.558426\n",
       "1st Flr SF         0.621676\n",
       "Total Bsmt SF      0.632280\n",
       "Garage Area        0.640401\n",
       "Garage Cars        0.647877\n",
       "Gr Liv Area        0.706780\n",
       "Overall Qual       0.799262\n",
       "SalePrice          1.000000\n",
       "Name: SalePrice, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which features correlate strongly with our target column, SalePrice\n",
    "\n",
    "abs_corr_coeffs = numerical_df.corr()[\"SalePrice\"].abs().sort_values()\n",
    "abs_corr_coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BsmtFin SF 1      0.432914\n",
       "Fireplaces        0.474558\n",
       "TotRms AbvGrd     0.495474\n",
       "Mas Vnr Area      0.508285\n",
       "Garage Yr Blt     0.526965\n",
       "Year Remod/Add    0.532974\n",
       "Full Bath         0.545604\n",
       "Year Built        0.558426\n",
       "1st Flr SF        0.621676\n",
       "Total Bsmt SF     0.632280\n",
       "Garage Area       0.640401\n",
       "Garage Cars       0.647877\n",
       "Gr Liv Area       0.706780\n",
       "Overall Qual      0.799262\n",
       "SalePrice         1.000000\n",
       "Name: SalePrice, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's only keep columns with a correlation coefficient of larger than 0.4 (arbitrary, worth experimenting later!)\n",
    "abs_corr_coeffs[abs_corr_coeffs > 0.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns with less than 0.4 correlation with SalePrice\n",
    "transform_df = numerical_df.drop(abs_corr_coeffs[abs_corr_coeffs<0.4].index, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which categorical columns should we keep?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of column names from documentation that are *meant* to be categorical\n",
    "nominal_features = [\"PID\", \"MS SubClass\", \"MS Zoning\", \"Street\", \"Alley\", \"Land Contour\", \"Lot Config\", \"Neighborhood\", \n",
    "                    \"Condition 1\", \"Condition 2\", \"Bldg Type\", \"House Style\", \"Roof Style\", \"Roof Matl\", \"Exterior 1st\", \n",
    "                    \"Exterior 2nd\", \"Mas Vnr Type\", \"Foundation\", \"Heating\", \"Central Air\", \"Garage Type\", \n",
    "                    \"Misc Feature\", \"Sale Type\", \"Sale Condition\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Which columns are currently numerical but need to be encoded as categorical instead (because the numbers don't have any semantic meaning)?\n",
    "* If a categorical column has hundreds of unique values (or categories), should we keep it? When we dummy code this column, hundreds of columns will need to be added back to the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MS SubClass',\n",
       " 'MS Zoning',\n",
       " 'Street',\n",
       " 'Land Contour',\n",
       " 'Lot Config',\n",
       " 'Neighborhood',\n",
       " 'Condition 1',\n",
       " 'Condition 2',\n",
       " 'Bldg Type',\n",
       " 'House Style',\n",
       " 'Roof Style',\n",
       " 'Roof Matl',\n",
       " 'Exterior 1st',\n",
       " 'Exterior 2nd',\n",
       " 'Foundation',\n",
       " 'Heating',\n",
       " 'Central Air']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which categorical columns have we still carried with us? We'll test these \n",
    "transform_cat_cols = []\n",
    "for col in nominal_features:\n",
    "    if col in transform_df.columns:\n",
    "        transform_cat_cols.append(col)\n",
    "\n",
    "transform_cat_cols\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Central Air      2\n",
       "Street           2\n",
       "Land Contour     4\n",
       "Lot Config       5\n",
       "Bldg Type        5\n",
       "Heating          6\n",
       "Roof Style       6\n",
       "Foundation       6\n",
       "MS Zoning        7\n",
       "Condition 2      8\n",
       "House Style      8\n",
       "Roof Matl        8\n",
       "Condition 1      9\n",
       "Exterior 1st    16\n",
       "MS SubClass     16\n",
       "Exterior 2nd    17\n",
       "Neighborhood    28\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many unique values in each categorical column?\n",
    "uniqueness_counts = transform_df[transform_cat_cols].apply(lambda col:len(col.value_counts())).sort_values()\n",
    "uniqueness_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Exterior 1st', 'MS SubClass', 'Exterior 2nd', 'Neighborhood'], dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aribtrary cutoff of 10 unique values (worth experimenting)\n",
    "\n",
    "drop_nonuniq_cols = uniqueness_counts[uniqueness_counts>10].index\n",
    "drop_nonuniq_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MS Zoning</th>\n",
       "      <th>Lot Area</th>\n",
       "      <th>Street</th>\n",
       "      <th>Lot Shape</th>\n",
       "      <th>Land Contour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>Lot Config</th>\n",
       "      <th>Land Slope</th>\n",
       "      <th>Condition 1</th>\n",
       "      <th>Condition 2</th>\n",
       "      <th>...</th>\n",
       "      <th>Open Porch SF</th>\n",
       "      <th>Enclosed Porch</th>\n",
       "      <th>3Ssn Porch</th>\n",
       "      <th>Screen Porch</th>\n",
       "      <th>Pool Area</th>\n",
       "      <th>Misc Val</th>\n",
       "      <th>Yr Sold</th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>Years Before Sale</th>\n",
       "      <th>Years Since Remod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RL</td>\n",
       "      <td>31770</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>...</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>215000</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RH</td>\n",
       "      <td>11622</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>105000</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  MS Zoning  Lot Area Street Lot Shape Land Contour Utilities Lot Config  \\\n",
       "0        RL     31770   Pave       IR1          Lvl    AllPub     Corner   \n",
       "1        RH     11622   Pave       Reg          Lvl    AllPub     Inside   \n",
       "\n",
       "  Land Slope Condition 1 Condition 2  ... Open Porch SF Enclosed Porch  \\\n",
       "0        Gtl        Norm        Norm  ...            62              0   \n",
       "1        Gtl       Feedr        Norm  ...             0              0   \n",
       "\n",
       "   3Ssn Porch  Screen Porch Pool Area Misc Val  Yr Sold SalePrice  \\\n",
       "0           0             0         0        0     2010    215000   \n",
       "1           0           120         0        0     2010    105000   \n",
       "\n",
       "  Years Before Sale Years Since Remod  \n",
       "0                50                50  \n",
       "1                49                49  \n",
       "\n",
       "[2 rows x 55 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_df = transform_df.drop(drop_nonuniq_cols, axis = 1)\n",
    "transform_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select just the remaining text columns and convert to categorical\n",
    "\n",
    "text_cols  = transform_df.select_dtypes(include = [\"object\"])\n",
    "\n",
    "for col in text_cols:\n",
    "    transform_df[col] = transform_df[col].astype(\"category\")\n",
    "    transform_df = pd.concat([transform_df, pd.get_dummies(transform_df[col])], axis = 1)\n",
    "    transform_df.drop(col, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or \n",
    "# transform_df = pd.concat([\n",
    "#     transform_df, \n",
    "#     pd.get_dummies(transform_df.select_dtypes(include=['category']))\n",
    "# ], axis=1).drop(text_cols,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_features(df):\n",
    "    num_missing = df.isnull().sum()\n",
    "    drop_missing_cols = num_missing[(num_missing > len(df)/20)].sort_values()\n",
    "    df = df.drop(drop_missing_cols.index, axis=1)\n",
    "    \n",
    "    text_mv_counts = df.select_dtypes(include=['object']).isnull().sum().sort_values(ascending=False)\n",
    "    drop_missing_cols_2 = text_mv_counts[text_mv_counts > 0]\n",
    "    df = df.drop(drop_missing_cols_2.index, axis=1)\n",
    "    \n",
    "    num_missing = df.select_dtypes(include=['integer', 'float']).isnull().sum()\n",
    "    fixable_numeric_cols = num_missing[(num_missing < len(df)/20) & (num_missing > 0)].sort_values()\n",
    "    replacement_values_dict = df[fixable_numeric_cols.index].mode().to_dict(orient='records')[0]\n",
    "    df = df.fillna(replacement_values_dict)\n",
    "    \n",
    "    years_sold = df['Yr Sold'] - df['Year Built']\n",
    "    years_since_remod = df['Yr Sold'] - df['Year Remod/Add']\n",
    "    df['Years Before Sale'] = years_sold\n",
    "    df['Years Since Remod'] = years_since_remod\n",
    "    df = df.drop([1702, 2180, 2181], axis=0)\n",
    "\n",
    "    df = df.drop([\"PID\", \"Order\", \"Mo Sold\", \"Sale Condition\", \"Sale Type\", \"Year Built\", \"Year Remod/Add\"], axis=1)\n",
    "    return df\n",
    "\n",
    "def select_features(df, coeff_threshold=0.4, uniq_threshold=10):\n",
    "    numerical_df = df.select_dtypes(include=['integer', 'float'])\n",
    "    abs_corr_coeffs = numerical_df.corr()[\"SalePrice\"].abs().sort_values()\n",
    "    df = df.drop(abs_corr_coeffs[abs_corr_coeffs < coeff_threshold].index, axis=1)\n",
    "    \n",
    "    nominal_features = [\"PID\", \"MS SubClass\", \"MS Zoning\", \"Street\", \"Alley\", \"Land Contour\", \"Lot Config\", \"Neighborhood\", \n",
    "                    \"Condition 1\", \"Condition 2\", \"Bldg Type\", \"House Style\", \"Roof Style\", \"Roof Matl\", \"Exterior 1st\", \n",
    "                    \"Exterior 2nd\", \"Mas Vnr Type\", \"Foundation\", \"Heating\", \"Central Air\", \"Garage Type\", \n",
    "                    \"Misc Feature\", \"Sale Type\", \"Sale Condition\"]\n",
    "    \n",
    "    transform_cat_cols = []\n",
    "    for col in nominal_features:\n",
    "        if col in df.columns:\n",
    "            transform_cat_cols.append(col)\n",
    "\n",
    "    uniqueness_counts = df[transform_cat_cols].apply(lambda col: len(col.value_counts())).sort_values()\n",
    "    drop_nonuniq_cols = uniqueness_counts[uniqueness_counts > 10].index\n",
    "    df = df.drop(drop_nonuniq_cols, axis=1)\n",
    "    \n",
    "    text_cols = df.select_dtypes(include=['object'])\n",
    "    for col in text_cols:\n",
    "        df[col] = df[col].astype('category')\n",
    "    df = pd.concat([df, pd.get_dummies(df.select_dtypes(include=['category']))], axis=1).drop(text_cols,axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def train_and_test(df, k=0):\n",
    "    numeric_df = df.select_dtypes(include=['integer', 'float'])\n",
    "    features = numeric_df.columns.drop(\"SalePrice\")\n",
    "    lr = LinearRegression()\n",
    "    \n",
    "    if k == 0: #  holdout validation\n",
    "        train = df[:1460]\n",
    "        test = df[1460:]\n",
    "\n",
    "        lr.fit(train[features], train[\"SalePrice\"])\n",
    "        predictions = lr.predict(test[features])\n",
    "        mse = mean_squared_error(test[\"SalePrice\"], predictions)\n",
    "        rmse = np.sqrt(mse)\n",
    "\n",
    "        return rmse\n",
    "    \n",
    "    if k == 1: # simple cross validation\n",
    "        # Randomize *all* rows (frac=1) from `df` and return\n",
    "        shuffled_df = df.sample(frac=1, )\n",
    "        train = df[:1460]\n",
    "        test = df[1460:]\n",
    "        \n",
    "        lr.fit(train[features], train[\"SalePrice\"])\n",
    "        predictions_one = lr.predict(test[features])        \n",
    "        \n",
    "        mse_one = mean_squared_error(test[\"SalePrice\"], predictions_one)\n",
    "        rmse_one = np.sqrt(mse_one)\n",
    "        \n",
    "        lr.fit(test[features], test[\"SalePrice\"])\n",
    "        predictions_two = lr.predict(train[features])        \n",
    "       \n",
    "        mse_two = mean_squared_error(train[\"SalePrice\"], predictions_two)\n",
    "        rmse_two = np.sqrt(mse_two)\n",
    "        \n",
    "        avg_rmse = np.mean([rmse_one, rmse_two])\n",
    "        print(rmse_one)\n",
    "        print(rmse_two)\n",
    "        return avg_rmse\n",
    "    else: # k-fold cross validation\n",
    "        kf = KFold(n_splits=k, shuffle=True)\n",
    "        rmse_values = []\n",
    "        for train_index, test_index, in kf.split(df):\n",
    "            train = df.iloc[train_index]\n",
    "            test = df.iloc[test_index]\n",
    "            lr.fit(train[features], train[\"SalePrice\"])\n",
    "            predictions = lr.predict(test[features])\n",
    "            mse = mean_squared_error(test[\"SalePrice\"], predictions)\n",
    "            rmse = np.sqrt(mse)\n",
    "            rmse_values.append(rmse)\n",
    "        print(rmse_values)\n",
    "        avg_rmse = np.mean(rmse_values)\n",
    "        return avg_rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"AmesHousing.txt\", delimiter=\"\\t\")\n",
    "transform_df = transform_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = select_features(transform_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29261.18245958932, 24941.692056570882, 27853.305266774158, 34938.545788573065]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "29248.681392876853"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse = train_and_test(filtered_df, k=4)\n",
    "\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
